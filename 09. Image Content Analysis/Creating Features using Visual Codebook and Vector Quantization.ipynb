{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cPickle as pickle\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from star_detector import StarFeatureDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_training_data(input_folder):\n",
    "    training_data = []\n",
    "    \n",
    "    if not os.path.isdir(input_folder):\n",
    "        raise IOError(\"The folder \" + input_folder + \" doesn't exist\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for filename in (x for x in files if x.endswith('.jpg')):\n",
    "            filepath = os.path.join(root, filename)\n",
    "            object_class = filepath.split('/')[-2]\n",
    "            training_data.append({\n",
    "                'object_class': object_class,\n",
    "                'image_path': filepath\n",
    "            })\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureBuilder(object):\n",
    "    \n",
    "    def extract_features(self, img):\n",
    "        keypoints = StarFeatureDetector().detect(img)\n",
    "        keypoints, feature_vectors = compute_sift_features(img, keypoints)\n",
    "        return feature_vectors\n",
    "\n",
    "    def get_codewords(self, input_map, scaling_size, max_samples=12):\n",
    "        keypoints_all = []\n",
    "        \n",
    "        count = 0\n",
    "        cur_class = ''\n",
    "        for item in input_map:\n",
    "            if count >= max_samples:\n",
    "                if cur_class != item['object_class']:\n",
    "                    count = 0\n",
    "                else:\n",
    "                    continue\n",
    "            count += 1\n",
    "            \n",
    "            if count == max_samples:\n",
    "                print(\"Built centroids for \", item['object_class'])\n",
    "                \n",
    "            cur_class = item['object_class']\n",
    "            img = cv2.imread(item['image_path'])\n",
    "            img = resize_image(img, scaling_size)\n",
    "            \n",
    "            num_dims = 128\n",
    "            feature_vectors = self.extract_features(img)\n",
    "            keypoints_all.extend(feature_vectors)\n",
    "            \n",
    "        kmeans, centroids = BagOfWords().cluster(keypoints_all)\n",
    "        \n",
    "        return kmeans, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfWords(object):\n",
    "    \n",
    "    def __init__(self, num_clusters=32):\n",
    "        self.num_dims = 128\n",
    "        self.num_clusters = num_clusters\n",
    "        self.num_retries = 10\n",
    "        \n",
    "    def cluster(self, datapoints):\n",
    "        kmeans = KMeans(self.num_clusters,\n",
    "                       n_init=max(self.num_retries, 1),\n",
    "                       max_iter=10, tol=1.0)\n",
    "        \n",
    "        res = kmeans.fit(datapoints)\n",
    "        centroids = res.cluster_centers_\n",
    "        \n",
    "        return kmeans, centroids\n",
    "    \n",
    "    def normalize(self, input_data):\n",
    "        sum_input = np.sum(input_data)\n",
    "        \n",
    "        if sum_input > 0:\n",
    "            return input_data/sum_input\n",
    "        else:\n",
    "            return input_data\n",
    "        \n",
    "    def construct_feature(self, img, kmeans, centroids):\n",
    "        keypoints = StarFeatureDetector().detect(img)\n",
    "        keypoints, feature_vectors = compute_sift_features(img, keypoints)\n",
    "        labels = kmeans.predict(feature_vectors)\n",
    "        feature_vector = np.zeros(self.num_clusters)\n",
    "        \n",
    "        for i,item in enumerate(feature_vectors):\n",
    "            feature_vector[labels[i]] += 1\n",
    "            \n",
    "        feature_vector_img = np.reshape(feature_vector, \n",
    "                                        ((1, feature_vector.shape[0])))\n",
    "        return self.normalize(feature_vector_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_map(input_map, kmeans, centroids, scaling_size):\n",
    "    feature_map = []\n",
    "    \n",
    "    for item in input_map:\n",
    "        temp_dict = {}\n",
    "        temp_dict['object_class'] = item['object_class']\n",
    "        \n",
    "        print(\"Extracting features for \", item['image_path'])\n",
    "        img = cv2.imread(item['image_path'])\n",
    "        img = resize_image(img, scaling_size)\n",
    "        \n",
    "        temp_dict['feature_vector'] = BagOfWords().construct_feature(\n",
    "                                        img, kmeans, centroids)\n",
    "        \n",
    "        if temp_dict['feature_vector'] is not None:\n",
    "            feature_map.append(temp_dict)\n",
    "            \n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_sift_features(img, keypoints):\n",
    "    if img is None:\n",
    "        raise TypeError('Invalid input image')\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    keypoints, descriptors = cv2.xfeatures2d.SIFT_create().compute(img_gray, keypoints)\n",
    "    \n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(input_img, new_size):\n",
    "    h, w = input_img.shape[:2]\n",
    "    scaling_factor = new_size / float(h)\n",
    "    \n",
    "    if w<h:\n",
    "        scaling_factor = new_size / float(w)\n",
    "    \n",
    "    new_shape = (int(w * scaling_factor), int(h * scaling_factor))\n",
    "    return cv2.resize(input_img, new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = load_training_data('training_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Building Visual Codebook ======\n",
      "('Built centroids for ', 'airplanes')\n",
      "('Built centroids for ', 'cars')\n",
      "('Built centroids for ', 'motorbikes')\n"
     ]
    }
   ],
   "source": [
    "print(\"====== Building Visual Codebook ======\")\n",
    "kmeans, centroids = FeatureBuilder().get_codewords(training_data, 200)\n",
    "\n",
    "with open('codebook.pkl', 'wb') as f:\n",
    "    pickle.dump((kmeans, centroids), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Building the Feature Map ======\n",
      "('Extracting features for ', 'training_images/airplanes/0001.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0002.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0003.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0004.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0005.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0006.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0007.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0008.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0009.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0010.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0011.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0012.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0013.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0014.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0015.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0016.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0017.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0018.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0019.jpg')\n",
      "('Extracting features for ', 'training_images/airplanes/0020.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0001.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0101.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0122.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0134.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0139.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0150.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0161.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0178.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0211.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0253.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0284.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0289.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0294.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0356.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0379.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0445.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0467.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0503.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0508.jpg')\n",
      "('Extracting features for ', 'training_images/cars/image_0526.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0001.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0002.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0003.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0004.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0005.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0006.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0007.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0008.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0009.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0010.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0011.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0012.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0013.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0014.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0015.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0016.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0017.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0018.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0019.jpg')\n",
      "('Extracting features for ', 'training_images/motorbikes/0020.jpg')\n"
     ]
    }
   ],
   "source": [
    "print(\"====== Building the Feature Map ======\")\n",
    "feature_map = get_feature_map(training_data, kmeans,\n",
    "                             centroids, 200)\n",
    "\n",
    "with open('feature_map.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
